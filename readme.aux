\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Objective}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Setup}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Class \texttt  {Multi\_layer\_perceptron}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments and Findings}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of mean difference between the two gradients for the parameters against the pair of layers they were connecting}}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of mean squared difference between the two gradients for the parameters against the pair of layers they were connecting}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Performance of various single hidden layer neural network architectures with the tanh activation function. }}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Performance of various single hidden layer neural network architectures with the relu activation function. }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparative Performance of various single hidden layer neural network architectures with the relu and tanh activation functions. }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of various optimizers in the given setting (25 neurons in middle layer). }}{4}}
\bibdata{ref}
\bibstyle{plain}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance of various optimizers in the given setting (100 neurons in middle layer). }}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Performance of various optimizers in the given setting (100, 25 neurons in the second and third layer respectively). }}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Performance of the network as a function of network depth }}{6}}
